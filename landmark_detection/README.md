**Results(NME/%) on WFLW dataset**

| Method | Fullset | Pose | Expression | Illumination | Make-up | Occlusion | Blur |
| :-----------------: | :-----------: | :------: | :------: | :------: | :------: | :------: | :------: |
| DVLN | 6.08 | 11.54 | 6.78 | 5.73 | 5.98 | 7.33 | 6.88 |
| LAB | 5.27 | 10.24 | 5.51 | 5.23 | 5.15 | 6.79 | 6.32 |
| SAN | 5.22 | 10.39 | 5.71 | 5.19 | 5.49 | 6.83 | 5.80 |
| WING | 5.11 | 8.75 | 5.36 | 4.93 | 5.41 | 6.37 | 5.81 |
| ResNet-18 | 6.09 | 10.76 | 6.97 | 5.83 | 6.19 | 7.15 | 6.67 |
| **AVS(ResNet-18)** | 5.25 | 9.10 | 5.83 | 4.93 | 5.47 | 6.26 | 5.86 |
| **AVS(LAB)** | **4.76** | **8.21** | **5.14** | **4.51** | **5.00** | **5.76** | **5.43** |
| **AVS(SAN)** | **4.39** | **8.42** | **4.68** | **4.24** | **4.37** | **5.60** | **4.86** |

We provide training codes for facial landmark detection using our style-augmented samples here. This provided example uses the same codebase and network strucutre in [SAN](https://d-x-y.github.io/publication/style-aggregation-network), implemented in [PyTorch](pytorch.org). The provided training scripts and parameters are able to obtain the results in our paper. You can also exploit similar training strategies to your own models and codebase.

## Preparation
You cam refer to the original [SAN codebase](https://github.com/TheSouthFrog/SAN) for the basic preparation before training.


### Dependencies
- [Python3.6](https://www.anaconda.com/download/#linux)
- [PyTorch=0.4](http://pytorch.org/)
- [torchvision](http://pytorch.org/docs/master/torchvision)

### Datasets Download
- Download the original WFLW dataset.
- Provide generated dataset as well as the annotations. We provide a synthetic WFLW dataset generated by this method here [Google Drive](https://drive.google.com/file/d/1bddYn6zQHFORKqZXm5vYTwB4Mn2UKwGb/view?usp=sharing) or [Baidu Drive](https://pan.baidu.com/s/1cJl_sL7NoQFApomTTv6-ew). Don't forget to modify the ```train_list``` and ```eval_lists``` directory.

### Training Script

We provide the training scripts of models on WFLW dataset and on augmented-WFLW dataset in ```./scripts/```


You can also download the model(AVS(SAN)) here [Google Drive](https://drive.google.com/open?id=1ofTpgtKX9zNbyFuyL6JIEpnVlcDjgOPQ).

### Contact
If you have any questions, please feel free to contact the authors.
Shengju Qian sjqian@cse.cuhk.edu.hk

### Citation

If you use our code or models, please consider citing our paper:

```
@inproceedings{qian2019aggregation,
  title={Aggregation via Separation: Boosting Facial Landmark Detector with Semi-Supervised Style Translation},
  author={Qian, Shengju and Sun, Keqiang and Wu, Wayne and Qian, Chen and Jia, Jiaya},
  journal={ICCV},
  year={2019}
}
